<!DOCTYPE html>
<html lang="en"><head>

    <meta name="generator" content="Hugo 0.152.2">
    <meta name="date" content="2025-10-24T15:31:49Z">
    
    <meta charset="utf-8">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="referrer" content="no-referrer">
    
    <meta name="author" content="Amit Dhurandhar, Amir-Hossein Karimi, Sara Magliacane, Stefano Teso, Efthymia Tsamoura, Zhe Zheng" />
    <meta name="description" content="Workshop on Unifying Concept Representation Learning (ICLR 2026)" />
    <meta name="keywords" content="workshop, concepts, explainable AI, neuro-symbolic AI, causal representation learning" />
    
    <title>CRL @ UAI 2022 | Home</title>
    
    <meta property="og:title" content="Home" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="Workshop on Unifying Concept Representation Learning (ICLR 2026)" />
    
    <meta name="twitter:title" content="" />
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;1,300&display=swap" rel="stylesheet"> 
    
    <link rel="canonical" href="https://ucrl-iclr26.github.io/">
    <link rel="stylesheet" href="https://ucrl-iclr26.github.io/styles.css">
    
    <link rel="apple-touch-icon" sizes="180x180" href="https://ucrl-iclr26.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://ucrl-iclr26.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://ucrl-iclr26.github.io/favicon-16x16.png">
    <link rel="manifest" href="https://ucrl-iclr26.github.io/site.webmanifest">

</head><body><section id="header">

    <div id="logo-container">
        <div id="title-inner-container">
            <a href="https://ucrl-iclr26.github.io/"><img src="https://ucrl-iclr26.github.io/logo.png" id="logo"></a>
        </div>
    </div>

    <div id="title-container">
        <div id="title-inner-container">
            <div class="supertitle">Workshop on</div>
            <div class="title"><a href="https://ucrl-iclr26.github.io/">Unifying Concept Representation Learning</a></div>
            <div class="subtitle">April 26-27 @ ICLR 2026</div>
        </div>
    </div>

    <br>

    <div id="navigation">
        <ul>
        
            <li><strong><a href="https://ucrl-iclr26.github.io/call-for-papers">Call for Papers</a></strong></li>
        
            <li><strong><a href="https://ucrl-iclr26.github.io/dates">Dates</a></strong></li>
        
            <li><strong><a href="https://ucrl-iclr26.github.io/formatting-instructions">Formatting Instructions</a></strong></li>
        
            <li><strong><a href="https://ucrl-iclr26.github.io/organisers-reviewers">Organisers</a></strong></li>
        
            <li><strong><a href="https://ucrl-iclr26.github.io/accepted-papers">Accepted Papers</a></strong></li>
        
            <li><strong><a href="https://ucrl-iclr26.github.io/schedule-format">Schedule and Format</a></strong></li>
        
            <li><strong><a href="https://ucrl-iclr26.github.io/invited-speakers">Invited Speakers</a></strong></li>
        
      </ul>
    </div>

</section><section id="content">
        
    <h1 id="welcome">Welcome!</h1>
<p>The <strong>Workshop on Unifying Concept Representation Learning (UCRL 2026)</strong> will
be co-located with <a href="https://iclr.cc/Conferences/2026"><strong>ICLR 2026</strong></a>, in Rio de
Janeiro, held on <strong>April 23-27, 2026.</strong></p>
<h2 id="about-the-workshop">About the workshop</h2>
<p>Several areas at the forefront of AI research are currently witnessing a
convergence of interests around the problem of <strong>learning high-quality concepts
from data</strong>. Concepts have become a central topic of study in <strong>neuro-symbolic
integration (NeSy)</strong>. NeSy approaches integrate perception – usually implemented
by a neural backbone – and symbolic reasoning by employing concepts to glue
together these two steps: the latter relies on the concepts detected by the
former to produce suitable outputs. Concepts are also used in <strong>Explainable AI
(XAI)</strong> by recent post-hoc explainers and self-explainable architectures as a
building block for constructing high-level justifications of model behavior.
Compared to, e.g., saliency maps, these can portray a more abstract and
understandable picture of the machine’s reasoning process, potentially
improving understandability, interactivity, and trustworthiness, to the point
that concepts have been called the lingua franca of human-AI interaction.</p>
<p>NeSy and XAI methods hinge on learned concepts being “high-quality”. Concepts
with misaligned semantics may compromise the meaning of model explanations,
reliability of NeSy architectures and human understanding of the underlying
systems. Recent works propose to leverage disentangled representations to
mitigate concept leakage, i.e., the presence of irrelevant information in the
learned concepts. <strong>Causal Representation Learning (CRL)</strong> is a generalization
of disentangled representation learning, when the latent variables are
dependent on each other, e.g., due to causal relations.</p>
<p>The potential of leveraging CRL to learn more robust and leak-proof concepts is
an emerging area of research with a growing number of approaches, but many open
questions remain. In particular, what properties high-quality concepts should
satisfy is unclear. Moreover, despite studying the same underlying object,
research in NeSy, XAI and CRL is proceeding on mostly independent tracks, with
minimal knowledge transfer. Separate branches differ in their working
definitions of what concepts are and what desiderata they ought to satisfy, on
what data and algorithms they should be learned with, and on how to properly
assess their quality. This also means that approaches in one area often ignore
insights from the others. As a result, the central issue of how to properly
learn and evaluate concepts is largely unanswered.</p>
<p>The aim of this ICLR 2026 workshop is to bring together researchers from NeSy,
XAI and CRL and from both industry and academia, who are interested in learning
robust, semantically meaningful concepts.</p>
<h2 id="important-dates">Important Dates</h2>
<ul>
<li><strong>Paper submission deadline:</strong> <strong>January 30, 2026, 23:59 AoE</strong></li>
<li><strong>Notification to authors:</strong> March 1, 2026, 23:59 AoE</li>
<li><strong>Camera-ready version:</strong> March 27, 2026, 23:59 AoE</li>
<li><strong>Workshop Date:</strong> April, 2026</li>
</ul>
<p>Contact us at <a href="mailto:ucrl.iclr2026@gmail.com">ucrl.iclr2026@gmail.com</a></p>
<h2 id="submission-link">Submission link</h2>
<p><a href="https://openreview.net/group?id=ICLR.cc/2026/Workshop/UCRL">https://openreview.net/group?id=ICLR.cc/2026/Workshop/UCRL</a></p>


    </section>
<div id="footer">
    Made with <a href="https://gohugo.io/">Hugo</a> and hosted on <a href="https://github.com/UCRL-ICLR26/ucrl-iclr26.github.io/">GitHub</a>.
</div>


</body>

</html>